AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template to create a pipeline for building and deploying CDK V2 application (Python backend with TypeScript/React frontend)'

Parameters:
  SourceType:
    Description: Source type for the CDK code
    Type: String
    Default: Git
    AllowedValues:
      - Git
      - S3PresignedURL

  GitRepositoryUrl:
    Description: URL of the public Git repository (e.g., https://github.com/username/repository.git)
    Type: String
    Default: 'https://github.com/aws-solutions-library-samples/guidance-for-medialake'

  S3PresignedURL:
    Description: Presigned URL for downloading the CDK code ZIP (if S3PresignedURL source type is selected)
    Type: String
    Default: ''

  InitialUserEmail:
    Description: Initial Media Lake administrator user email
    Type: String
    AllowedPattern: '[^@]+@[^@]+\.[^@]+'

  InitialUserFirstName:
    Description: Initial Media Lake administrator first name
    Type: String
    MinLength: 1
    MaxLength: 50
    AllowedPattern: '^[a-zA-Z\s\-\.]+$'

  InitialUserLastName:
    Description: Initial Media Lake administrator last name
    Type: String
    MinLength: 1
    MaxLength: 50
    AllowedPattern: '^[a-zA-Z\s\-\.]+$'

  MediaLakeEnvironmentName:
    Description: Media Lake environment name (dev, prd, ...)
    Type: String
    MinLength: 1
    MaxLength: 10
    AllowedPattern: ^[a-zA-Z0-9]*$
    Default: dev

  OpenSearchDeploymentSize:
    Description: OpenSearch deployment size
    Type: String
    Default: small
    AllowedValues:
      - small
      - medium
      - large

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: Initial Media Lake User
        Parameters:
          - InitialUserEmail
          - InitialUserFirstName
          - InitialUserLastName
      -
        Label:
          default: Media Lake Configuration
        Parameters:
          - MediaLakeEnvironmentName
          - OpenSearchDeploymentSize
      -
        Label:
          default: Media Lake Deployment Configuration
        Parameters:
          - SourceType
          - GitRepositoryUrl
          - S3PresignedURL
    ParameterLabels:
      InitialUserEmail:
        default: Email
      InitialUserFirstName:
        default: First Name
      InitialUserLastName:
        default: Last Name
      MediaLakeEnvironmentName:
        default: Media Lake Environment Name
      OpenSearchDeploymentSize:
        default: OpenSearch Deployment Size
      SourceType:
        default: Source Type
      GitRepositoryUrl:
        default: Git Repository URL
      S3PresignedURL:
        default: S3 Presigned URL

Conditions:
  IsGitSource: !Equals [!Ref SourceType, 'Git']
  IsS3PresignedURLSource: !Equals [!Ref SourceType, 'S3PresignedURL']
  NeedsInitialSourcePackage: !Or [!Equals [!Ref SourceType, 'Git'], !Equals [!Ref SourceType, 'S3PresignedURL']]

Resources:
  # Add the Service Linked Role Manager resources first
  ServiceLinkedRoleFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ServiceLinkedRoleManagerRole.Arn
      Runtime: python3.12
      Timeout: 300
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def check_and_create_role(service_name):
              """Check if service-linked role exists and create if it doesn't"""
              iam = boto3.client('iam')
              role_name = f"AWSServiceRoleFor{service_name.split('.')[0].upper()}"

              try:
                  # Check if role exists
                  iam.get_role(RoleName=role_name)
                  logger.info(f"Role {role_name} already exists")
                  return True
              except iam.exceptions.NoSuchEntityException:
                  try:
                      # Create service-linked role
                      iam.create_service_linked_role(AWSServiceName=service_name)
                      logger.info(f"Created service-linked role for {service_name}")
                      return True
                  except Exception as e:
                      error_message = str(e).lower()
                      if 'role already exists' in error_message or 'has been taken in this account' in error_message:
                          logger.info(f"Role already exists for {service_name}")
                          return True
                      logger.error(f"Error creating role for {service_name}: {str(e)}")
                      return False
              except Exception as e:
                  logger.error(f"Error checking role {role_name}: {str(e)}")
                  return False

          def handler(event, context):
              logger.info(f"Received event: {event}")

              # List of services that need service-linked roles
              services = [
                  'es.amazonaws.com',
                  'opensearchservice.amazonaws.com',
                  'osis.amazonaws.com'
              ]

              response_data = {}

              if event['RequestType'] in ['Create', 'Update']:
                  success = True
                  for service in services:
                      if not check_and_create_role(service):
                          success = False
                          response_data['Error'] = f"Failed to create role for {service}"
                          break

                  status = cfnresponse.SUCCESS if success else cfnresponse.FAILED
                  cfnresponse.send(event, context, status, response_data)
              else:
                  # Delete event - nothing to clean up as service-linked roles are managed by AWS
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)

  ServiceLinkedRoleManagerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      Policies:
        - PolicyName: ServiceLinkedRoleManagement
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:GetRole'
                Resource: '*'

  ServiceLinkedRoleManager:
    Type: Custom::ServiceLinkedRoleManager
    DependsOn: ServiceLinkedRoleFunction
    Properties:
      ServiceToken: !GetAtt ServiceLinkedRoleFunction.Arn

  # Modify existing IAM roles to depend on ServiceLinkedRoleManager
  CodeBuildServiceRole:
    Type: 'AWS::IAM::Role'
    DependsOn: ServiceLinkedRoleManager
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'
      Policies:
        - PolicyName: CodeBuildAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                  - 's3:GetObjectVersion'
                Resource:
                  - !Sub 'arn:aws:s3:::${ArtifactBucket}/*'
              - Effect: Allow
                Action:
                  - 'ecr:GetAuthorizationToken'
                  - 'ecr:BatchCheckLayerAvailability'
                  - 'ecr:GetDownloadUrlForLayer'
                  - 'ecr:BatchGetImage'
                  - 'ecr:InitiateLayerUpload'
                  - 'ecr:UploadLayerPart'
                  - 'ecr:CompleteLayerUpload'
                  - 'ecr:PutImage'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 'ec2:DescribeAvailabilityZones'
                Resource: '*'

  CDKDeployRole:
    Type: 'AWS::IAM::Role'
    DependsOn: ServiceLinkedRoleManager
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AdministratorAccess'

  CodePipelineServiceRole:
    Type: 'AWS::IAM::Role'
    DependsOn: ServiceLinkedRoleManager
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codepipeline.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AWSCodeBuildAdminAccess'
      Policies:
        - PolicyName: CodePipelineAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                  - 's3:GetObjectVersion'
                  - 's3:GetBucketVersioning'
                  - 's3:ListBucket'
                Resource:
                  - !Sub 'arn:aws:s3:::${ArtifactBucket}'
                  - !Sub 'arn:aws:s3:::${ArtifactBucket}/*'

  # S3 Bucket for Artifacts
  ArtifactBucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldArtifacts
            Status: Enabled
            ExpirationInDays: 30
          - Id: CleanupBeforeDeletion
            Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 1
            NoncurrentVersionExpiration:
              NoncurrentDays: 1
            ExpiredObjectDeleteMarker: true

  # Initial source package for S3-based and Git-based pipelines
  InitialSourcePackage:
    Type: 'Custom::S3InitialFile'
    Condition: NeedsInitialSourcePackage
    Properties:
      ServiceToken: !GetAtt InitialSourceFunction.Arn
      BucketName: !Ref ArtifactBucket
      SourceKey: 'source-package.zip'
      Content: !Sub |
        This is a source placeholder for the MediaLakeCDKPipeline pipeline.
        Created on ${AWS::StackName} in ${AWS::Region}.
        Timestamp: ${AWS::AccountId}

  InitialSourceFunction:
    Type: 'AWS::Lambda::Function'
    Condition: NeedsInitialSourcePackage
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.12
      Timeout: 30
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import io
          import zipfile
          import time

          def handler(event, context):
              if event['RequestType'] in ['Create', 'Update']:
                  try:
                      s3 = boto3.client('s3')
                      bucket_name = event['ResourceProperties']['BucketName']
                      source_key = event['ResourceProperties']['SourceKey']
                      content = event['ResourceProperties']['Content']

                      # Create a simple ZIP file in memory
                      buffer = io.BytesIO()
                      with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as z:
                          # Add a README file
                          z.writestr('README.md', content)
                          # Add a timestamp file
                          z.writestr('timestamp.txt', str(time.time()))

                      buffer.seek(0)

                      # Upload the ZIP file to S3
                      s3.put_object(
                          Bucket=bucket_name,
                          Key=source_key,
                          Body=buffer.getvalue()
                      )

                      response_data = {'Message': 'Initial source package created'}
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
                  except Exception as e:
                      print(f"Error: {str(e)}")
                      response_data = {'Error': str(e)}
                      cfnresponse.send(event, context, cfnresponse.FAILED, response_data)
              else:  # Delete
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})

  LambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Condition: NeedsInitialSourcePackage
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:PutObject'
                Resource: !Sub 'arn:aws:s3:::${ArtifactBucket}/*'

  # CodeBuild Projects
  # Git Clone Project for public repositories
  GitCloneProject:
    Type: 'AWS::CodeBuild::Project'
    Condition: IsGitSource
    DependsOn:
      - ServiceLinkedRoleManager
      - InitialSourcePackage
    Properties:
      Name: 'MediaLakeCDKPipeline-GitClone'
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:5.0
        EnvironmentVariables:
          - Name: GIT_REPOSITORY_URL
            Value: !Ref GitRepositoryUrl
          - Name: GIT_BRANCH
            Value: main
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
          version: 0.2
          phases:
            install:
              runtime-versions:
                python: 3.12
              commands:
                - 'echo "Installing git"'
                - 'yum update -y'
                - 'yum install -y git'
            build:
              commands:
                - 'echo "Cloning repository from $GIT_REPOSITORY_URL"'
                - 'echo "Branch: $GIT_BRANCH"'
                - 'git clone --depth 1 --branch $GIT_BRANCH $GIT_REPOSITORY_URL source/'
                - 'echo "Listing cloned content structure"'
                - 'find source -type d | sort'
                - 'echo "Copying files to working directory"'
                - 'cp -r source/* .'
                - 'echo "Directory structure after copy"'
                - 'find . -maxdepth 3 -type d | sort'
            post_build:
              commands:
                - 'echo "Git clone completed"'
          artifacts:
            files:
              - "**/*"
              - "!source/**/*"

  DownloadSourceProject:
    Type: 'AWS::CodeBuild::Project'
    Condition: IsS3PresignedURLSource
    DependsOn:
      - ServiceLinkedRoleManager
      - InitialSourcePackage
    Properties:
      Name: 'MediaLakeCDKPipeline-DownloadSource'
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:5.0
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
          version: 0.2
          phases:
            install:
              runtime-versions:
                python: 3.12
            build:
              commands:
                - 'echo "Downloading source code from presigned URL"'
                - 'curl -L "${S3PresignedURL}" -o source-code.zip'
                - 'mkdir -p source'
                - 'unzip -o source-code.zip -d source/'
                - 'echo "Listing downloaded content structure"'
                - 'find source -type d | sort'
                - 'echo "Copying files to working directory"'
                - 'cp -r source/* .'
                - 'echo "Directory structure after copy"'
                - 'find . -maxdepth 3 -type d | sort'
            post_build:
              commands:
                - 'echo "Download completed"'
          artifacts:
            files:
              - '**/*'
              - '!source-code.zip'
              - '!source/**/*'

  BuildProject:
    Type: 'AWS::CodeBuild::Project'
    DependsOn: ServiceLinkedRoleManager
    Properties:
      Name: 'MediaLakeCDKPipeline-BuildProject'
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:5.0
        PrivilegedMode: true
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
          version: 0.2
          env:
            variables:
              CI: CODEBUILD
              CDK_DEFAULT_ACCOUNT: ${AWS::AccountId}
              CDK_DEFAULT_REGION: ${AWS::Region}
          phases:
            install:
              runtime-versions:
                python: 3.12
                nodejs: 20
              commands:
                - echo "Installing dependencies"
                - yum install jq
                - npm install -g aws-cdk
                - npm install -g esbuild
                - pip install -U pip
                - export CDK_DIR=$(if [ -d "./cdk" ]; then echo "./cdk"; else find . -type f -name "cdk.json" -o -name "app.py" | grep -v "node_modules" | head -1 | xargs dirname; fi)
                - export FRONTEND_DIR=$(if [ -d "./medialake_user_interface" ]; then echo "./medialake_user_interface"; elif [ -d "./frontend" ]; then echo "./frontend"; else find . -name "package.json" -not -path "*/node_modules/*" | head -1 | xargs dirname; fi)
                - echo "CDK directory $CDK_DIR"
                - echo "Frontend directory $FRONTEND_DIR"
                - if [ -z "$CDK_DIR" ]; then echo "Could not find CDK directory"; exit 1; fi
                - if [ -z "$FRONTEND_DIR" ]; then echo "Could not find frontend directory"; exit 1; fi
                - cd $CDK_DIR
                - if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
                - if [ -f "requirements-dev.txt" ]; then pip install -r requirements-dev.txt; fi
                - if [ -f "package.json" ]; then npm install; fi
                - cd $CODEBUILD_SRC_DIR/$FRONTEND_DIR
                - if [ -f "package.json" ]; then npm install; fi
            pre_build:
              commands:
                - echo "Preparing config file"
                - cd $CODEBUILD_SRC_DIR/$CDK_DIR
                - if [ -f "config.json" ]; then echo "Using existing config file"; else echo "Creating config file"; cp .cicd/config.json-template config.json; fi
                - echo "$( jq --arg e "${MediaLakeEnvironmentName}" '.environment = $e' config.json )" > config.json
                - echo "$( jq --arg a "${AWS::AccountId}" '.account_id = $a' config.json )" > config.json
                - echo "$( jq --arg r "${AWS::Region}" '.primary_region = $r' config.json )" > config.json
                - echo "$( jq --arg u "${InitialUserEmail}" '.initial_user.email = $u' config.json )" > config.json
                - echo "$( jq --arg f "${InitialUserFirstName}" '.initial_user.first_name = $f' config.json )" > config.json
                - echo "$( jq --arg l "${InitialUserLastName}" '.initial_user.last_name = $l' config.json )" > config.json
                - echo "$( jq --arg s "${OpenSearchDeploymentSize}" '.opensearch_deployment_size = $s' config.json )" > config.json
            build:
              commands:
                - echo "Building frontend"
                - cd $CODEBUILD_SRC_DIR/$FRONTEND_DIR
                - if [ -f "package.json" ]; then npm run build || echo "Frontend Build failed, continuing"; fi
                - export BUILD_DIR=$(if [ -d "build" ]; then echo "build"; elif [ -d "dist" ]; then echo "dist"; else find . -maxdepth 2 -type d -name "build" -o -name "dist" | head -1 | xargs basename; fi)
                - if [ -z "$BUILD_DIR" ]; then echo "Could not find build output directory, creating empty one"; mkdir -p build; export BUILD_DIR="build"; fi
                - echo "Build output directory $BUILD_DIR"
                - cd $CODEBUILD_SRC_DIR/$CDK_DIR
                - mkdir -p assets
                - if [ -d "$CODEBUILD_SRC_DIR/$FRONTEND_DIR/$BUILD_DIR" ]; then echo "Copying frontend build from $FRONTEND_DIR/$BUILD_DIR to $CDK_DIR/assets"; cp -r "$CODEBUILD_SRC_DIR/$FRONTEND_DIR/$BUILD_DIR/" assets/; else echo "No frontend build found to copy"; fi
                - echo "Building Lambda functions"
                - python3 .cicd/build_lambdas.py build
                - echo "Building FFprobe"
                - bash .cicd/build_ffprobe.sh
                - echo "Building FFmpeg"
                - bash .cicd/build_ffmpeg.sh
                - echo "Building RSSVG"
                - bash .cicd/build_resvg.sh
                # - cdk synth || (echo "CDK synth failed" && find . -name "cdk.json" -o -name "app.py" | grep -v "node_modules")
                - echo "CDK synthesis"
                - cdk synth || (echo "CDK synth failed" && exit 1)
            post_build:
              commands:
                - echo "Build completed"
          artifacts:
            files:
              - "**/*"
            base-directory: '.'
      TimeoutInMinutes: 120

  DeployProject:
    Type: 'AWS::CodeBuild::Project'
    DependsOn: ServiceLinkedRoleManager
    Properties:
      Name: 'MediaLakeCDKPipeline-DeployProject'
      ServiceRole: !GetAtt CDKDeployRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:5.0
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
          version: 0.2
          env:
            variables:
              CI: CODEBUILD
              CDK_DEFAULT_ACCOUNT: ${AWS::AccountId}
              CDK_DEFAULT_REGION: ${AWS::Region}
          phases:
            install:
              runtime-versions:
                python: 3.12
                nodejs: 20
              commands:
                - echo Installing dependencies
                - npm install -g aws-cdk
                - pip install -U pip
                - echo "Locating CDK directory"
                - export CDK_DIR=$(if [ -d "./cdk" ]; then echo "./cdk"; else find . -type f -name "cdk.json" -o -name "app.py" | grep -v "node_modules" | head -1 | xargs dirname; fi)
                - echo "CDK directory $CDK_DIR"
                - if [ -z "$CDK_DIR" ]; then echo "Could not find CDK directory"; exit 1; fi
                - cd $CDK_DIR
                - if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
            build:
              commands:
                - echo Deploying CDK stacks
                - cd $CODEBUILD_SRC_DIR/$CDK_DIR
                # Bootstrap current region
                - cdk bootstrap
                # Also bootstrap us-east-1 if we're not already in that region
                - 'if [ "${AWS::Region}" != "us-east-1" ]; then echo "Also bootstrapping us-east-1 for CloudFront WAF deployment"; cdk bootstrap aws://${AWS::AccountId}/us-east-1; fi'
                # Deploy all stacks
                - cdk deploy --all --require-approval never || (echo "CDK deploy failed" && exit 1)
            post_build:
              commands:
                - echo Deployment completed
          artifacts:
            files:
              - "**/*"
            base-directory: '.'
      TimeoutInMinutes: 120

  # Pipeline with Git Source
  GitSourcePipeline:
    Type: 'AWS::CodePipeline::Pipeline'
    Condition: IsGitSource
    DependsOn:
      - InitialSourcePackage
      - GitCloneProject
      - BuildProject
      - DeployProject
    Properties:
      Name: MediaLakeCDKPipeline
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket
      Stages:
        - Name: Source
          Actions:
            - Name: Source
              ActionTypeId:
                Category: Source
                Owner: AWS
                Provider: S3
                Version: '1'
              Configuration:
                S3Bucket: !Ref ArtifactBucket
                S3ObjectKey: 'source-package.zip'
                PollForSourceChanges: true
              OutputArtifacts:
                - Name: PlaceholderSource

        - Name: Clone
          Actions:
            - Name: CloneFromGitHub
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref GitCloneProject
              InputArtifacts:
                - Name: PlaceholderSource
              OutputArtifacts:
                - Name: SourceCode

        - Name: Build
          Actions:
            - Name: BuildCode
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref BuildProject
              InputArtifacts:
                - Name: SourceCode
              OutputArtifacts:
                - Name: BuildOutput

        - Name: Deploy
          Actions:
            - Name: DeployCDK
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref DeployProject
              InputArtifacts:
                - Name: BuildOutput

  # Pipeline with S3 PresignedURL Source
  S3SourcePipeline:
    Type: 'AWS::CodePipeline::Pipeline'
    Condition: IsS3PresignedURLSource
    DependsOn:
      - InitialSourcePackage
      - DownloadSourceProject
      - BuildProject
      - DeployProject
    Properties:
      Name: MediaLakeCDKPipeline
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket
      Stages:
        - Name: Source
          Actions:
            - Name: Source
              ActionTypeId:
                Category: Source
                Owner: AWS
                Provider: S3
                Version: '1'
              Configuration:
                S3Bucket: !Ref ArtifactBucket
                S3ObjectKey: 'source-package.zip'
                PollForSourceChanges: true
              OutputArtifacts:
                - Name: PlaceholderSource

        - Name: Download
          Actions:
            - Name: DownloadFromPresignedURL
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref DownloadSourceProject
              InputArtifacts:
                - Name: PlaceholderSource
              OutputArtifacts:
                - Name: SourceCode

        - Name: Build
          Actions:
            - Name: BuildCode
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref BuildProject
              InputArtifacts:
                - Name: SourceCode
              OutputArtifacts:
                - Name: BuildOutput

        - Name: Deploy
          Actions:
            - Name: DeployCDK
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref DeployProject
              InputArtifacts:
                - Name: BuildOutput

  # Custom resource to empty the S3 bucket on deletion
  S3BucketCleanup:
    Type: Custom::S3BucketCleanup
    Properties:
      ServiceToken: !GetAtt S3BucketCleanupFunction.Arn
      BucketName: !Ref ArtifactBucket

  S3BucketCleanupFunction:
    Type: AWS::Lambda::Function
    DependsOn: ArtifactBucket
    Properties:
      Handler: index.handler
      Role: !GetAtt S3BucketCleanupRole.Arn
      Runtime: python3.12
      Timeout: 300
      Code:
        ZipFile: |
          import json
          import boto3
          import cfnresponse
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def delete_bucket_contents(bucket_name):
              """Delete all objects and object versions from the bucket"""
              try:
                  s3 = boto3.resource('s3')
                  bucket = s3.Bucket(bucket_name)

                  # Delete all object versions
                  logger.info(f"Deleting all object versions from {bucket_name}")
                  bucket.object_versions.all().delete()

                  # Delete all objects (in case versioning is not enabled)
                  logger.info(f"Deleting all objects from {bucket_name}")
                  bucket.objects.all().delete()

                  return True
              except Exception as e:
                  logger.error(f"Error emptying bucket {bucket_name}: {str(e)}")
                  return False

          def handler(event, context):
              logger.info(f"Received event: {json.dumps(event)}")

              # Extract the bucket name from the event
              bucket_name = event['ResourceProperties']['BucketName']
              response_data = {}

              if event['RequestType'] == 'Delete':
                  logger.info(f"Emptying bucket {bucket_name}")
                  success = delete_bucket_contents(bucket_name)

                  if success:
                      logger.info(f"Successfully emptied bucket {bucket_name}")
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
                  else:
                      logger.error(f"Failed to empty bucket {bucket_name}")
                      cfnresponse.send(event, context, cfnresponse.FAILED, response_data)
              else:
                  # For Create and Update events, just succeed
                  logger.info(f"No action needed for {event['RequestType']} event")
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)

  S3BucketCleanupRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      Policies:
        - PolicyName: S3BucketCleanupPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:ListBucket'
                  - 's3:ListBucketVersions'
                Resource: !Sub 'arn:aws:s3:::${ArtifactBucket}'
              - Effect: Allow
                Action:
                  - 's3:DeleteObject'
                  - 's3:DeleteObjectVersion'
                  - 's3:GetObject'
                  - 's3:GetObjectVersion'
                Resource: !Sub 'arn:aws:s3:::${ArtifactBucket}/*'

Outputs:
  PipelineUrl:
    Description: URL to the CodePipeline console
    Value: !If
      - IsGitSource
      - !Sub https://console.aws.amazon.com/codepipeline/home?region=${AWS::Region}#/view/${GitSourcePipeline}
      - !Sub https://console.aws.amazon.com/codepipeline/home?region=${AWS::Region}#/view/${S3SourcePipeline}

  ArtifactBucketName:
    Description: Name of the S3 bucket used to store pipeline artifacts
    Value: !Ref ArtifactBucket
